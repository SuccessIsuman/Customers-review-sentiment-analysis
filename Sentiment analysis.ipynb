{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\isuman success\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\isuman success\\anaconda3\\lib\\site-packages (from nltk) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing needed library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the various dataset\n",
    "trainData=pd.read_csv('Train.csv')\n",
    "validData=pd.read_csv('Valid.csv')\n",
    "testData=pd.read_csv('Test.csv')\n",
    "# merging the entire dataset as one\n",
    "df=pd.concat([trainData,validData,testData], axis=0)\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset: (40000, 2)\n",
      "testing dataset: (5000, 2)\n",
      "validation dataset: (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print('training dataset:', trainData.shape)\n",
    "print('testing dataset:', testData.shape)\n",
    "print('validation dataset:', validData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trining dataset:\n",
      " 0    20019\n",
      "1    19981\n",
      "Name: label, dtype: int64\n",
      "testing dataset:\n",
      " 1    2505\n",
      "0    2495\n",
      "Name: label, dtype: int64\n",
      "validayion dataset:\n",
      " 1    2514\n",
      "0    2486\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "trainData.label.value_counts()\n",
    "print('trining dataset:\\n', trainData.label.value_counts())\n",
    "print('testing dataset:\\n', testData.label.value_counts())\n",
    "print('validayion dataset:\\n', validData.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veiwing how a single review looks like\n",
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sentiment (25000, 2)\n",
      "Negative sentiment (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Positive sentiment', df[df['label']==1].shape)\n",
    "print('Negative sentiment',df[df['label']==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0         151\n",
       "1  When I put this movie in my DVD player, and sa...      0         326\n",
       "2  Why do people who do not know what a particula...      0         184\n",
       "3  Even though I have great interest in Biblical ...      0          69\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1         178"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"a function Checking the lenght of the reviews\"\"\"\n",
    "df['word_count']=df['text'].apply(lambda x:len(x.split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0         151   \n",
       "1  When I put this movie in my DVD player, and sa...      0         326   \n",
       "2  Why do people who do not know what a particula...      0         184   \n",
       "3  Even though I have great interest in Biblical ...      0          69   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1         178   \n",
       "\n",
       "   char_count  \n",
       "0         874  \n",
       "1        1811  \n",
       "2         983  \n",
       "3         351  \n",
       "4         983  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Calculating number of characters in each review\"\"\"\n",
    "df['char_count']=df['text'].apply(lambda x:len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function that Calculating the averge word count of each review\"\"\"\n",
    "def average_word(x):\n",
    "    words=x.split()\n",
    "    return sum(len(word) for word in words)/len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>874</td>\n",
       "      <td>4.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>1811</td>\n",
       "      <td>4.558282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>983</td>\n",
       "      <td>4.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>351</td>\n",
       "      <td>4.101449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>983</td>\n",
       "      <td>4.528090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0         151   \n",
       "1  When I put this movie in my DVD player, and sa...      0         326   \n",
       "2  Why do people who do not know what a particula...      0         184   \n",
       "3  Even though I have great interest in Biblical ...      0          69   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1         178   \n",
       "\n",
       "   char_count  average_word  \n",
       "0         874      4.794702  \n",
       "1        1811      4.558282  \n",
       "2         983      4.347826  \n",
       "3         351      4.101449  \n",
       "4         983      4.528090  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['average_word']=df['text'].apply(average_word)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Isuman\n",
      "[nltk_data]     success\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word</th>\n",
       "      <th>stopwords_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>874</td>\n",
       "      <td>4.794702</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>1811</td>\n",
       "      <td>4.558282</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>983</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>351</td>\n",
       "      <td>4.101449</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>983</td>\n",
       "      <td>4.528090</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0         151   \n",
       "1  When I put this movie in my DVD player, and sa...      0         326   \n",
       "2  Why do people who do not know what a particula...      0         184   \n",
       "3  Even though I have great interest in Biblical ...      0          69   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1         178   \n",
       "\n",
       "   char_count  average_word  stopwords_count  \n",
       "0         874      4.794702               64  \n",
       "1        1811      4.558282              164  \n",
       "2         983      4.347826               85  \n",
       "3         351      4.101449               36  \n",
       "4         983      4.528090               68  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function that counts the number of stop words from the dataset\n",
    "df['stopwords_count']=df['text'].apply(lambda x:len(\n",
    "    [word for word in x.split() if word.lower() in stop_words]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the review= 11557847\n",
      "Average number of words per review= 231.15694\n",
      "Standard deviation = 171.34399728366566\n"
     ]
    }
   ],
   "source": [
    "# average number of words per review\n",
    "total_words= df['word_count'].sum()\n",
    "word_per_review=df['word_count'].mean()\n",
    "std=df['word_count'].std()\n",
    "print('Total number of words in the review=', total_words)\n",
    "print('Average number of words per review=', word_per_review)\n",
    "print('Standard deviation =', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate of stopwords in the dataset\n",
    "df['stopwords_rate']= df['stopwords_count'] / df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>stopwords_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>874</td>\n",
       "      <td>4.794702</td>\n",
       "      <td>64</td>\n",
       "      <td>0.423841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>1811</td>\n",
       "      <td>4.558282</td>\n",
       "      <td>164</td>\n",
       "      <td>0.503067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>983</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>85</td>\n",
       "      <td>0.461957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>351</td>\n",
       "      <td>4.101449</td>\n",
       "      <td>36</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>983</td>\n",
       "      <td>4.528090</td>\n",
       "      <td>68</td>\n",
       "      <td>0.382022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0         151   \n",
       "1  When I put this movie in my DVD player, and sa...      0         326   \n",
       "2  Why do people who do not know what a particula...      0         184   \n",
       "3  Even though I have great interest in Biblical ...      0          69   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1         178   \n",
       "\n",
       "   char_count  average_word  stopwords_count  stopwords_rate  \n",
       "0         874      4.794702               64        0.423841  \n",
       "1        1811      4.558282              164        0.503067  \n",
       "2         983      4.347826               85        0.461957  \n",
       "3         351      4.101449               36        0.521739  \n",
       "4         983      4.528090               68        0.382022  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>average_word</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>stopwords_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>231.156940</td>\n",
       "      <td>1309.431020</td>\n",
       "      <td>4.640676</td>\n",
       "      <td>103.850160</td>\n",
       "      <td>0.450721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500005</td>\n",
       "      <td>171.343997</td>\n",
       "      <td>989.728014</td>\n",
       "      <td>0.340731</td>\n",
       "      <td>76.874169</td>\n",
       "      <td>0.048660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.239865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>4.417904</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>970.000000</td>\n",
       "      <td>4.627006</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.452115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>1590.250000</td>\n",
       "      <td>4.847458</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.482558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2470.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "      <td>12.290909</td>\n",
       "      <td>1053.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label    word_count    char_count  average_word  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.500000    231.156940   1309.431020      4.640676   \n",
       "std        0.500005    171.343997    989.728014      0.340731   \n",
       "min        0.000000      4.000000     32.000000      1.239865   \n",
       "25%        0.000000    126.000000    699.000000      4.417904   \n",
       "50%        0.500000    173.000000    970.000000      4.627006   \n",
       "75%        1.000000    280.000000   1590.250000      4.847458   \n",
       "max        1.000000   2470.000000  13704.000000     12.290909   \n",
       "\n",
       "       stopwords_count  stopwords_rate  \n",
       "count     50000.000000    50000.000000  \n",
       "mean        103.850160        0.450721  \n",
       "std          76.874169        0.048660  \n",
       "min           0.000000        0.000000  \n",
       "25%          57.000000        0.421053  \n",
       "50%          79.000000        0.452115  \n",
       "75%         125.000000        0.482558  \n",
       "max        1053.000000        0.666667  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Text pre-preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole process of pre-preprocessing in a sequencial order the process involves the following: \n",
    "\n",
    "1. Removal of punctuation, numerical values and special characters\n",
    "2. conver the text to lowercase\n",
    "3. Removal of stopwords\n",
    "4. Tokenizing the Data\n",
    "5. part of speach tagging\n",
    "6. normalization of the data using Lemmatization\n",
    "7. Determining  word density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df[['text','label']]\n",
    "data=data.loc[:100]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Removal of punctuation, numbers and special characters from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explanation:  “clean” is the function that takes text as input and returns the text without \n",
    "any punctuation marks or numbers or special characters in it. We applied it to the ‘text’ column \n",
    "and created a new column called ‘clean_text’ which contained the cleaned text.\n",
    "\"\"\"\n",
    "import string\n",
    "def clean(text):\n",
    "    clean_word=\"\".join(word for word in text if not word.isdigit() \n",
    "                       and word not in string.punctuation)\n",
    "    return clean_word\n",
    "data[\"clean_text\"]=data['text'].apply(clean)\n",
    "\n",
    "# def clean(text):\n",
    "# # Removes all special characters and numericals leaving the alphabets\n",
    "#     text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "#     return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>I grew up b  watching and loving the Thunderbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>When I put this movie in my DVD player and sat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1  When I put this movie in my DVD player, and sa...      0   \n",
       "2  Why do people who do not know what a particula...      0   \n",
       "3  Even though I have great interest in Biblical ...      0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  I grew up b  watching and loving the Thunderbi...  \n",
       "1  When I put this movie in my DVD player and sat...  \n",
       "2  Why do people who do not know what a particula...  \n",
       "3  Even though I have great interest in Biblical ...  \n",
       "4  Im a die hard Dads Army fan and nothing will e...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. conerting all the review text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text\"]=data[\"clean_text\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "in this data set we will not only remove the general stop words but also remove \n",
    "the indeginous stopwords of whom a few is saved as other_stopwords as generated above.\n",
    "\"\"\"\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words('english')\n",
    "data[\"clean_text\"]=data[\"clean_text\"].apply(lambda x: \" \".join(word for word in x.split() \n",
    "                                                              if word not in stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>grew b watching loving thunderbirds mates scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd player sat coke chips expectatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>even though great interest biblical movies bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>im die hard dads army fan nothing ever change ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Released in December of 1957, Sayonara went on...</td>\n",
       "      <td>1</td>\n",
       "      <td>released december sayonara went earn oscar nom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>War, Inc. - Corporations take over war in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>war inc corporations take war future use lone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What is your freaking problem? Do you have not...</td>\n",
       "      <td>1</td>\n",
       "      <td>freaking problem nothing better sit fat asses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dick and Jane Harper (Jim Carrey, Téa Leoni) w...</td>\n",
       "      <td>0</td>\n",
       "      <td>dick jane harper jim carrey téa leoni wind une...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>In the history of cinema, every great film-mak...</td>\n",
       "      <td>1</td>\n",
       "      <td>history cinema every great filmmaker create fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "0    I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1    When I put this movie in my DVD player, and sa...      0   \n",
       "2    Why do people who do not know what a particula...      0   \n",
       "3    Even though I have great interest in Biblical ...      0   \n",
       "4    Im a die hard Dads Army fan and nothing will e...      1   \n",
       "..                                                 ...    ...   \n",
       "96   Released in December of 1957, Sayonara went on...      1   \n",
       "97   War, Inc. - Corporations take over war in the ...      0   \n",
       "98   What is your freaking problem? Do you have not...      1   \n",
       "99   Dick and Jane Harper (Jim Carrey, Téa Leoni) w...      0   \n",
       "100  In the history of cinema, every great film-mak...      1   \n",
       "\n",
       "                                            clean_text  \n",
       "0    grew b watching loving thunderbirds mates scho...  \n",
       "1    put movie dvd player sat coke chips expectatio...  \n",
       "2    people know particular time past like feel nee...  \n",
       "3    even though great interest biblical movies bor...  \n",
       "4    im die hard dads army fan nothing ever change ...  \n",
       "..                                                 ...  \n",
       "96   released december sayonara went earn oscar nom...  \n",
       "97   war inc corporations take war future use lone ...  \n",
       "98   freaking problem nothing better sit fat asses ...  \n",
       "99   dick jane harper jim carrey téa leoni wind une...  \n",
       "100  history cinema every great filmmaker create fi...  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Creating a list of other stop words that are indegious to our reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "br          193\n",
       "film        143\n",
       "movie       129\n",
       "one          91\n",
       "like         86\n",
       "           ... \n",
       "dark         15\n",
       "original     15\n",
       "since        15\n",
       "around       14\n",
       "takes        14\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Explanation: first we convert all the reviews to a single string\n",
    "then we split it into a list of words\n",
    "afterwards we convert it into a pandas series \n",
    "so we can count the number of time a word appears in the entire data frame\n",
    "just to know the words that occurs most and remove the stop words that has \n",
    "no contribution to the meaning ot the reviews\"\"\"\n",
    "pd.Series(\"\".join(data[\"clean_text\"]).split()).value_counts()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scanning through the top 100 most occuring words and pick out words that has no cotribution \n",
    "#to the meaning of the reviews as stop words\n",
    "other_stopword=['br','one','get','would','even','time','also','first','make','made','could','way',\n",
    "              'think','two','plot','know','life','still','say','end','man','somthing','go','back','b',\n",
    "              'im','thing','years','actually','makes','though','us','thats','things','seems','around',\n",
    "              'young','take','however','got','enough','world','give','thought','may','gets','theres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. removing other stop words that are indeginous to our text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text\"]=data[\"clean_text\"].apply(lambda x: \" \".join(word for word in x.split() \n",
    "                                                              if word not in other_stopword))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d. removing low frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating a list of words that appear only once of twice which will likely be a typo error\"\"\"\n",
    "wordCount=pd.Series(\"\".join(data[\"clean_text\"]).split()).value_counts().rename_axis('stopwords')\n",
    "wordCount=wordCount.reset_index(name='counts')\n",
    "low_freq=list(wordCount[wordCount['counts']<=2]['stopwords'])\n",
    "\"\"\" Removing low frequescy words from the text dataset\"\"\"\n",
    "data[\"clean_text\"]=data[\"clean_text\"].apply(lambda x: \" \".join(word for word in x.split() \n",
    "                                                              if word not in low_freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>watching thunderbirds school watched played th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd sat expectations movie movie ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>people past like feel try others replace woods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>great movies death every minute movie everythi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>hard fan nothing ever every brand new film fil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1  When I put this movie in my DVD player, and sa...      0   \n",
       "2  Why do people who do not know what a particula...      0   \n",
       "3  Even though I have great interest in Biblical ...      0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  watching thunderbirds school watched played th...  \n",
       "1  put movie dvd sat expectations movie movie ani...  \n",
       "2  people past like feel try others replace woods...  \n",
       "3  great movies death every minute movie everythi...  \n",
       "4  hard fan nothing ever every brand new film fil...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenizing the text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "in this data set we will tokenize the data with the RegexpTokenizer so that any missing\n",
    "characters which was hiding withing the text that was mixed by the punctuation removal function\n",
    "will be removed my the regex expression we can also use orthe\n",
    "A word tokenizer helps to break a sentence into a list of words\n",
    "\"\"\"\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "regexp_tokenizaer=RegexpTokenizer(\"[\\w*]+\") # @geek for geek\n",
    "tokens=data[\"clean_text\"].apply(lambda x: regexp_tokenizaer.tokenize(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Isuman success\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Isuman\n",
      "[nltk_data]     success\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download and import the needed part of speech tool kit\n",
    "\"\"\"\n",
    "Explanation: taging is the function that takes the a list of words called tokens\n",
    "and tags the words to their Part of speech. \n",
    "We applied it to the list of words obtained during tokenization and \n",
    "created a new column for ‘POS tagged’ data.\n",
    "To obtain the accurate Lemmatized word, the WordNetLemmatizer requires \n",
    "POS tags in the form of ‘n’, ‘a’, etc. But the POS tags obtained from \n",
    "pos_tag are in the form of ‘NN’, ‘ADJ’, etc.\n",
    "hence we map pos_tag to wordnet tags,  we created a dictionary pos_dict. \n",
    "Any pos_tag that starts with J is mapped to wordnet.ADJ, \n",
    "any pos_tag that starts with R is mapped to wordnet.ADV, and so on.Our tags of interest are Noun, \n",
    "Adjective, Adverb, Verb. Anything out of these four is mapped to None\n",
    "\"\"\"\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "def tagging(token):\n",
    "    newlist=[]\n",
    "    pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, \n",
    "                'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "    tags=pos_tag(token)\n",
    "#     return tags\n",
    "    for word, tag in tags:\n",
    "        newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\"\"\" Applying the above function to our dataset and saving the obtained as 'Pos tag'\"\"\"\n",
    "data['pos_tag']= tokens.apply(tagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>watching thunderbirds school watched played th...</td>\n",
       "      <td>[(watching, v), (thunderbirds, n), (school, n)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd sat expectations movie movie ani...</td>\n",
       "      <td>[(put, v), (movie, n), (dvd, n), (sat, v), (ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>people past like feel try others replace woods...</td>\n",
       "      <td>[(people, n), (past, v), (like, None), (feel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>great movies death every minute movie everythi...</td>\n",
       "      <td>[(great, a), (movies, n), (death, n), (every, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>hard fan nothing ever every brand new film fil...</td>\n",
       "      <td>[(hard, a), (fan, n), (nothing, n), (ever, r),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1  When I put this movie in my DVD player, and sa...      0   \n",
       "2  Why do people who do not know what a particula...      0   \n",
       "3  Even though I have great interest in Biblical ...      0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  watching thunderbirds school watched played th...   \n",
       "1  put movie dvd sat expectations movie movie ani...   \n",
       "2  people past like feel try others replace woods...   \n",
       "3  great movies death every minute movie everythi...   \n",
       "4  hard fan nothing ever every brand new film fil...   \n",
       "\n",
       "                                             pos_tag  \n",
       "0  [(watching, v), (thunderbirds, n), (school, n)...  \n",
       "1  [(put, v), (movie, n), (dvd, n), (sat, v), (ex...  \n",
       "2  [(people, n), (past, v), (like, None), (feel, ...  \n",
       "3  [(great, a), (movies, n), (death, n), (every, ...  \n",
       "4  [(hard, a), (fan, n), (nothing, n), (ever, r),...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. stemming of the data using Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explanation: lemmatize is a function that takes pos_tag tuples, \n",
    "and gives the Lemma for each word in pos_tag based on the pos of that word. \n",
    "We applied it to the ‘POS tagged’ column and created a column ‘Lemma’ to store the output.\n",
    "\"\"\"\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            word = word\n",
    "            lemma += \" \" + word\n",
    "        else:\n",
    "            word = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma += \" \" + word\n",
    "    return lemma\n",
    "\"\"\" Applying the above function to our dataset and saving the obtained as 'lemma'\"\"\"\n",
    "data['lemma']=data['pos_tag'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>watching thunderbirds school watched played th...</td>\n",
       "      <td>[(watching, v), (thunderbirds, n), (school, n)...</td>\n",
       "      <td>watch thunderbird school watch play thunderb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd sat expectations movie movie ani...</td>\n",
       "      <td>[(put, v), (movie, n), (dvd, n), (sat, v), (ex...</td>\n",
       "      <td>put movie dvd sit expectation movie movie an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>people past like feel try others replace woods...</td>\n",
       "      <td>[(people, n), (past, v), (like, None), (feel, ...</td>\n",
       "      <td>people past like feel try others replace woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>great movies death every minute movie everythi...</td>\n",
       "      <td>[(great, a), (movies, n), (death, n), (every, ...</td>\n",
       "      <td>great movie death every minute movie everyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>hard fan nothing ever every brand new film fil...</td>\n",
       "      <td>[(hard, a), (fan, n), (nothing, n), (ever, r),...</td>\n",
       "      <td>hard fan nothing ever every brand new film f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1  When I put this movie in my DVD player, and sa...      0   \n",
       "2  Why do people who do not know what a particula...      0   \n",
       "3  Even though I have great interest in Biblical ...      0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...      1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  watching thunderbirds school watched played th...   \n",
       "1  put movie dvd sat expectations movie movie ani...   \n",
       "2  people past like feel try others replace woods...   \n",
       "3  great movies death every minute movie everythi...   \n",
       "4  hard fan nothing ever every brand new film fil...   \n",
       "\n",
       "                                             pos_tag  \\\n",
       "0  [(watching, v), (thunderbirds, n), (school, n)...   \n",
       "1  [(put, v), (movie, n), (dvd, n), (sat, v), (ex...   \n",
       "2  [(people, n), (past, v), (like, None), (feel, ...   \n",
       "3  [(great, a), (movies, n), (death, n), (every, ...   \n",
       "4  [(hard, a), (fan, n), (nothing, n), (ever, r),...   \n",
       "\n",
       "                                               lemma  \n",
       "0    watch thunderbird school watch play thunderb...  \n",
       "1    put movie dvd sit expectation movie movie an...  \n",
       "2    people past like feel try others replace woo...  \n",
       "3    great movie death every minute movie everyth...  \n",
       "4    hard fan nothing ever every brand new film f...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>watch thunderbird school watch play thunderb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>put movie dvd sit expectation movie movie an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>people past like feel try others replace woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>great movie death every minute movie everyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>hard fan nothing ever every brand new film f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Released in December of 1957, Sayonara went on...</td>\n",
       "      <td>release oscar oscar best support actor role ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>War, Inc. - Corporations take over war in the ...</td>\n",
       "      <td>war corporation war future use brand john cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What is your freaking problem? Do you have not...</td>\n",
       "      <td>freak problem nothing well sit find somethin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dick and Jane Harper (Jim Carrey, Téa Leoni) w...</td>\n",
       "      <td>dick jane jim carrey line dick work catch tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>In the history of cinema, every great film-mak...</td>\n",
       "      <td>history cinema every great film many time be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    I grew up (b. 1965) watching and loving the Th...   \n",
       "1    When I put this movie in my DVD player, and sa...   \n",
       "2    Why do people who do not know what a particula...   \n",
       "3    Even though I have great interest in Biblical ...   \n",
       "4    Im a die hard Dads Army fan and nothing will e...   \n",
       "..                                                 ...   \n",
       "96   Released in December of 1957, Sayonara went on...   \n",
       "97   War, Inc. - Corporations take over war in the ...   \n",
       "98   What is your freaking problem? Do you have not...   \n",
       "99   Dick and Jane Harper (Jim Carrey, Téa Leoni) w...   \n",
       "100  In the history of cinema, every great film-mak...   \n",
       "\n",
       "                                                 lemma  \n",
       "0      watch thunderbird school watch play thunderb...  \n",
       "1      put movie dvd sit expectation movie movie an...  \n",
       "2      people past like feel try others replace woo...  \n",
       "3      great movie death every minute movie everyth...  \n",
       "4      hard fan nothing ever every brand new film f...  \n",
       "..                                                 ...  \n",
       "96     release oscar oscar best support actor role ...  \n",
       "97     war corporation war future use brand john cu...  \n",
       "98     freak problem nothing well sit find somethin...  \n",
       "99     dick jane jim carrey line dick work catch tr...  \n",
       "100    history cinema every great film many time be...  \n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at the original review text and the text after preprocessing  \n",
    "data[['text','lemma']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting th dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['lemma']\n",
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_X,, X_test, training_y, test_y=train_test_split(X,y, random_state=101, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most popular methods of feature extraction are :\n",
    "1. Bag-of-Words\n",
    "2. Term Frequency-Inverse Document Frequency(TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'did': 1, 'not': 2, 'like': 1, 'a': 1, 'good': 2, 'movie': 2}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Bag of Words model\n",
    "texts = {\n",
    "\"good movie\", \"not a good movie\", \"did not like\"\n",
    "}\n",
    "def Bag_of_words(dataset):\n",
    "    word2count = {}\n",
    "    for data in dataset:\n",
    "        words = nltk.word_tokenize(data)\n",
    "        for word in words:\n",
    "            if word not in word2count.keys():\n",
    "                word2count[word] = 1\n",
    "            else:\n",
    "                word2count[word] += 1\n",
    "    return word2count\n",
    "\"\"\" Applying the function to lemma column\"\"\"\n",
    "Bag_of_words(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Term Frequency-Inverse Document Frequency(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating tf-idf values for example\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "\"\"\" An Example\"\"\"\n",
    "# example = [\"good movie\", \"not a good movie\", \"did not like\", 'i hate it']\n",
    " \n",
    "# tfidf = TfidfVectorizer(ngram_range = (1,2))\n",
    "# features = tfidf.fit_transform(example)\n",
    " \n",
    "# pd.DataFrame(features.todense(), columns = tfidf.get_feature_names())\n",
    "\"\"\" Apply TF-IDF on our real dataset\"\"\"\n",
    "tfidf = TfidfVectorizer(min_df = 2,max_df = 0.5, ngram_range = (1,2))\n",
    "features = tfidf.fit_transform(data['lemma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting th dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
